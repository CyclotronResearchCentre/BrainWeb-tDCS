{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the effect of anode placement (vmPFC, bipolar)\n",
    "\n",
    "In this notebook, we evaluate the effect of the anode placement on the F7-F8 bipolar electrodes montage targetting the ventromedial prefrontal cortex (vmPFC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add utility package to path\n",
    "sys.path.append(os.environ.get(\"BRAINWEB_TDCS_CODE_DIR\", \"../code\"))\n",
    "from brainweb_tdcs import ROIS, EXPERIMENTS\n",
    "from brainweb_tdcs.study import get_experiments_for_roi\n",
    "from brainweb_tdcs.plot import (\n",
    "    display_side_by_side,\n",
    "    plot_placement_categorical,\n",
    "    plot_posterior,\n",
    ")\n",
    "\n",
    "# Set path data directory\n",
    "if \"BRAINWEB_TDCS_DATA_DIR\" not in os.environ:\n",
    "    os.environ[\"BRAINWEB_TDCS_DATA_DIR\"] = str((Path.cwd() / \"../data\").resolve())\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "CAPTIONS = {\n",
    "    \"e\": \"Magnitude of the\\nelectric field\",\n",
    "    \"e_r\": \"Magnitude of the\\nnormal component of electric field\",\n",
    "}\n",
    "LABELS = {\n",
    "    \"e\": \"$| \\mathbf{e} |$ (mVm$^{-1}$)\",\n",
    "    \"e_r\": \"$| \\mathbf{e}_r |$ (mVm$^{-1}$)\",\n",
    "}\n",
    "FUNC_DICT = {\n",
    "    \"mean\": np.mean,\n",
    "    \"std\": np.std,\n",
    "    \"2.5%\": lambda x: np.percentile(x, 2.5),\n",
    "    \"97.5%\": lambda x: np.percentile(x, 97.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiment\n",
    "\n",
    "We first select the experiment we want to process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "experiment = EXPERIMENTS[4]\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data\n",
    "\n",
    "The data regarding the anode placement is already formatted. The `\"p\"` column contains the name of the anode placement (`\"reference\"`, `\"anterior\"`, `\"central\"`, `\"lateral\"` and `\"posterior\"`) while the column `\"p_id\"` contains an integer ranging from $0$ to $4$ included ($0$ corresponding to the reference placement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = experiment.get_data()[[\"sub\", \"p\", \"p_id\", \"e\", \"e_r\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then display the results for the mangitude of the electric field $| \\pmb{e} |$ and of its component normal to the cortical surface $| \\pmb{e}_r |$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_placement_categorical(axs[0], \"e\", data, LABELS[\"e\"], CAPTIONS[\"e\"])\n",
    "plot_placement_categorical(axs[1], \"e_r\", data, LABELS[\"e_r\"], CAPTIONS[\"e_r\"])\n",
    "plt.show()\n",
    "columns = [\"mean\", \"std\", \"25%\", \"75%\"]\n",
    "display_side_by_side(\n",
    "    [\n",
    "        data.groupby(\"p\").describe()[\"e\"][columns],\n",
    "        data.groupby(\"p\").describe()[\"e_r\"][columns],\n",
    "    ],\n",
    "    [\"\", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the base model\n",
    "\n",
    "We can now model the differences between the means of the populations obtained with the four anode displacements and the reference one using the following Bayesian model:\n",
    "$$\n",
    "| \\pmb{e} | \\sim \\mathcal{N}(\\mu_{| \\pmb{e} |}, \\sigma_{| \\pmb{e} |}^2), \\\\\n",
    "| \\pmb{e}_r | \\sim \\mathcal{N}(\\mu_{| \\pmb{e}_r |}, \\sigma_{| \\pmb{e}_r |}^2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mu_{| \\pmb{e} |} = \\alpha_{| \\pmb{e} |} + \\sum_{p=1}^4 \\beta_{| \\pmb{e} |, p} \\cdot X_p + \\varepsilon_{| \\pmb{e} |}, \\\\\n",
    "\\mu_{| \\pmb{e}_r |} = \\alpha_{| \\pmb{e}_r |} + \\sum_{p=1}^4 \\beta_{| \\pmb{e}_r |, p} \\cdot X_p + \\varepsilon_{| \\pmb{e}_r |},\n",
    "$$\n",
    "\n",
    "The values of $X_p$ are either $1$ if the value in `\"p_id\"` is equal to $p$ or $0$. This way, the reference population is described by $\\alpha + \\varepsilon$ and the values of each $\\beta_p$ corresponds to the difference between the reference population and the measurements resulting from the $p$-th anode displacement. If $\\beta_p \\approx 0$, the anode displacement does not affect the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled model\n",
    "\n",
    "The first models we fit are fully pooled. This means that we do not account for any hierarchy in the data and instead consider all the samples as independent.\n",
    "\n",
    "These models are exactly the ones described above.\n",
    "\n",
    "### Fit the models\n",
    "\n",
    "Weakly informative priors are set automatically for $\\alpha$, $\\beta$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pooled_e = bmb.Model(f\"e ~ C(p_id)\", data)\n",
    "model_pooled_e_r = bmb.Model(f\"e_r ~ C(p_id)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "trace_pooled_e = model_pooled_e.fit(draws=1000, chains=4, random_seed=RANDOM_SEED)\n",
    "trace_pooled_e_r = model_pooled_e_r.fit(draws=1000, chains=4, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We display the probability density of $\\beta_p$ for both models as well as their $95$% HDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "idx = [\"alpha\", *[f\"beta_{p}\" for p in data[\"p\"].unique()[1:]], \"sigma\"]\n",
    "summary_pooled_e = az.summary(trace_pooled_e, stat_funcs=FUNC_DICT, extend=False)\n",
    "summary_pooled_e_r = az.summary(trace_pooled_e_r, stat_funcs=FUNC_DICT, extend=False)\n",
    "summary_pooled_e.index, summary_pooled_e_r.index = idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "l = len(idx[1:-1])\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 10), sharex=\"col\")\n",
    "for i, n in enumerate(idx[1:-1]):\n",
    "    suffix = n.split(\"_\")[1]\n",
    "    plot_posterior(\n",
    "        axs[i][0],\n",
    "        trace_pooled_e,\n",
    "        summary_pooled_e,\n",
    "        \"C(p_id)\",\n",
    "        LABELS[\"e\"] if i == l - 1 else \"\",\n",
    "        CAPTIONS[\"e\"] if i == 0 else \"\",\n",
    "        i,\n",
    "        summary_param=n,\n",
    "        show_zero=True,\n",
    "        beta_suffix=suffix,\n",
    "    )\n",
    "    plot_posterior(\n",
    "        axs[i][1],\n",
    "        trace_pooled_e_r,\n",
    "        summary_pooled_e_r,\n",
    "        \"C(p_id)\",\n",
    "        LABELS[\"e_r\"] if i == l - 1 else \"\",\n",
    "        CAPTIONS[\"e_r\"] if i == 0 else \"\",\n",
    "        i,\n",
    "        summary_param=n,\n",
    "        show_zero=True,\n",
    "        beta_suffix=suffix,\n",
    "    )\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "display_side_by_side([summary_pooled_e, summary_pooled_e_r], [\"\", \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical model\n",
    "\n",
    "Now, we consider the fact that multiple records were obtained with the same subject.\n",
    "\n",
    "To account for this, the definitions of the intercept $\\alpha$ and the slopes $\\beta_p$ become\n",
    "$$\n",
    "\\alpha_i = \\alpha_\\text{common} + \\alpha_{\\text{sub}_i}, \\\\\n",
    "\\beta_{p, i} = \\beta_{\\text{common}, p} + \\beta_{\\text{sub}_i, p}.\n",
    "$$\n",
    "\n",
    "Here, we differenciate the common value of the intercept $\\alpha_\\text{common}$ and of the slopes $\\beta_{\\text{common}, p}$ from the subject specific contributions $\\alpha_{\\text{sub}_i}$ and $\\beta_{\\text{sub}_i, p}$. These contributions are modelled as centered normal distributions\n",
    "$$\n",
    "\\alpha_\\text{sub} \\sim \\mathcal{N}(0, \\sigma_{\\alpha_\\text{sub}}), \\\\\n",
    "\\beta_{\\text{sub}, p} \\sim \\mathcal{N}(0, \\sigma_{\\beta_\\text{sub}, p}).\n",
    "$$\n",
    "\n",
    "Hence, the models become\n",
    "$$\n",
    "| \\pmb{e} | \\sim \\mathcal{N}(\\mu_{| \\pmb{e} |, i}, \\sigma_{| \\pmb{e} |}^2), \\\\\n",
    "| \\pmb{e}_r | \\sim \\mathcal{N}(\\mu_{| \\pmb{e}_r |, i}, \\sigma_{| \\pmb{e}_r |}^2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mu_{| \\pmb{e} |} = \\alpha_{| \\pmb{e} |, i} + \\sum_{p=1}^4 \\beta_{| \\pmb{e} |, p, i} \\cdot X_p + \\varepsilon_{| \\pmb{e} |}, \\\\\n",
    "\\mu_{| \\pmb{e}_r |} = \\alpha_{| \\pmb{e}_r |, i} + \\sum_{p=1}^4 \\beta_{| \\pmb{e}_r |, p, i} \\cdot X_p + \\varepsilon_{| \\pmb{e}_r |},\n",
    "$$\n",
    "\n",
    "### Fit the models\n",
    "\n",
    "Once again, weakly informative priors are automatically set for all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hierarchic_e = bmb.Model(f\"e ~ C(p_id) + (C(p_id) | sub)\", data)\n",
    "model_hierarchic_e_r = bmb.Model(f\"e_r ~ C(p_id) + (C(p_id) | sub)\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "trace_hierarchic_e = model_hierarchic_e.fit(\n",
    "    draws=1000, chains=4, random_seed=RANDOM_SEED, target_accept=0.9\n",
    ")\n",
    "trace_hierarchic_e_r = model_hierarchic_e_r.fit(\n",
    "    draws=1000, chains=4, random_seed=RANDOM_SEED, target_accept=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Again, we display the posteriors of $\\beta_p$ and their $95$% HDI for the two metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "idx = [\n",
    "    \"alpha\",\n",
    "    *[f\"beta_{p}\" for p in data[\"p\"].unique()[1:]],\n",
    "    \"sigma(alpha_sub)\",\n",
    "    *[f\"alpha_sub_{i}\" for i in range(len(data[\"sub\"].unique()))],\n",
    "    *[f\"sigma(beta_{p}_sub)\" for p in data[\"p\"].unique()[1:]],\n",
    "    *[\n",
    "        f\"beta_{p}_{i}\"\n",
    "        for p in data[\"p\"].unique()[1:]\n",
    "        for i in range(len(data[\"sub\"].unique()))\n",
    "    ],\n",
    "    \"sigma\",\n",
    "]\n",
    "summary_hierarchic_e = az.summary(\n",
    "    trace_hierarchic_e, stat_funcs=FUNC_DICT, extend=False\n",
    ")\n",
    "summary_hierarchic_e_r = az.summary(\n",
    "    trace_hierarchic_e_r, stat_funcs=FUNC_DICT, extend=False\n",
    ")\n",
    "summary_hierarchic_e.index, summary_hierarchic_e_r.index = idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "l = len(idx[1:5])\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 10), sharex=\"col\")\n",
    "for i, n in enumerate(idx[1:5]):\n",
    "    suffix = n.split(\"_\")[1]\n",
    "    plot_posterior(\n",
    "        axs[i][0],\n",
    "        trace_hierarchic_e,\n",
    "        summary_hierarchic_e,\n",
    "        \"C(p_id)\",\n",
    "        LABELS[\"e\"] if i == l - 1 else \"\",\n",
    "        CAPTIONS[\"e\"] if i == 0 else \"\",\n",
    "        i,\n",
    "        summary_param=n,\n",
    "        show_zero=True,\n",
    "        beta_suffix=suffix,\n",
    "    )\n",
    "    plot_posterior(\n",
    "        axs[i][1],\n",
    "        trace_hierarchic_e_r,\n",
    "        summary_hierarchic_e_r,\n",
    "        \"C(p_id)\",\n",
    "        LABELS[\"e_r\"] if i == l - 1 else \"\",\n",
    "        CAPTIONS[\"e_r\"] if i == 0 else \"\",\n",
    "        i,\n",
    "        summary_param=n,\n",
    "        show_zero=True,\n",
    "        beta_suffix=suffix,\n",
    "    )\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "rows = [\n",
    "    \"alpha\",\n",
    "    \"sigma(alpha_sub)\",\n",
    "    \"beta_anterior\",\n",
    "    \"sigma(beta_anterior_sub)\",\n",
    "    \"beta_central\",\n",
    "    \"sigma(beta_central_sub)\",\n",
    "    \"beta_lateral\",\n",
    "    \"sigma(beta_lateral_sub)\",\n",
    "    \"beta_posterior\",\n",
    "    \"sigma(beta_posterior_sub)\",\n",
    "    \"sigma\",\n",
    "]\n",
    "display_side_by_side(\n",
    "    [summary_hierarchic_e.loc[rows, :], summary_hierarchic_e_r.loc[rows, :]], [\"\", \"\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainweb-tdcs-analysis",
   "language": "python",
   "name": "brainweb-tdcs-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
