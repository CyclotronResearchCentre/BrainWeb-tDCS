{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare bipolar and unipolar electrodes montages (MC)\n",
    "\n",
    "In this notebook, we compare the effect of bipolar and unipolar electrodes montages targetting the motor cortex (MC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add utility package to path\n",
    "sys.path.append(os.environ.get(\"BRAINWEB_TDCS_CODE_DIR\", \"../code\"))\n",
    "from brainweb_tdcs import ROIS\n",
    "from brainweb_tdcs.study import get_experiments_for_roi\n",
    "from brainweb_tdcs.plot import (\n",
    "    display_side_by_side,\n",
    "    plot_bipolar_unipolar,\n",
    "    plot_posterior,\n",
    ")\n",
    "\n",
    "# Set path data directory\n",
    "if \"BRAINWEB_TDCS_DATA_DIR\" not in os.environ:\n",
    "    os.environ[\"BRAINWEB_TDCS_DATA_DIR\"] = str((Path.cwd() / \"../data\").resolve())\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "CAPTIONS = {\n",
    "    \"e\": \"Magnitude of the\\nelectric field\",\n",
    "    \"e_r\": \"Magnitude of the\\nnormal component of electric field\",\n",
    "}\n",
    "LABELS = {\n",
    "    \"e\": \"$| \\mathbf{e} |$ (mVm$^{-1}$)\",\n",
    "    \"e_r\": \"$| \\mathbf{e}_r |$ (mVm$^{-1}$)\",\n",
    "}\n",
    "FUNC_DICT = {\n",
    "    \"mean\": np.mean,\n",
    "    \"std\": np.std,\n",
    "    \"2.5%\": lambda x: np.percentile(x, 2.5),\n",
    "    \"97.5%\": lambda x: np.percentile(x, 97.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiments\n",
    "\n",
    "We have considered two different electrodes montages for the MC. The first used the C3-C4 bipolar electrodes montage while the second used the C3-Fp2 unipolar electrodes montage.\n",
    "\n",
    "We first select these experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "roi = ROIS[0]\n",
    "experiments = get_experiments_for_roi(roi)\n",
    "experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the data\n",
    "\n",
    "Now we load the results from both experiments and concatenate it to produce a single dataframe. We also add a `\"montage\"` column to keep track of which type of montage the records were acquired with (`\"bipolar\"` or `\"unipolar\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "for e in experiments:\n",
    "    df = e.get_data()\n",
    "    df[\"montage\"] = \"bipolar\" if e.is_bipolar else \"unipolar\"\n",
    "    dfs.append(df[[\"sub\", \"k\", \"montage\", \"e\", \"e_r\"]])\n",
    "data = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then display the results for the mangitude of the electric field $| \\pmb{e} |$ and of its component normal to the cortical surface $| \\pmb{e}_r |$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plot_bipolar_unipolar(axs[0], \"e\", data, LABELS[\"e\"], CAPTIONS[\"e\"])\n",
    "plot_bipolar_unipolar(axs[1], \"e_r\", data, LABELS[\"e_r\"], CAPTIONS[\"e_r\"])\n",
    "plt.show()\n",
    "columns = [\"mean\", \"std\", \"25%\", \"75%\"]\n",
    "display_side_by_side(\n",
    "    [\n",
    "        data.groupby(\"montage\").describe()[\"e\"][columns],\n",
    "        data.groupby(\"montage\").describe()[\"e_r\"][columns],\n",
    "    ],\n",
    "    [\"\", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the base model\n",
    "\n",
    "We can now model the difference between the means of the two populations (T-test) using the following Bayesian models:\n",
    "$$\n",
    "| \\pmb{e} | \\sim \\mathcal{N}(\\mu_{| \\pmb{e} |}, \\sigma_{| \\pmb{e} |}^2), \\\\\n",
    "| \\pmb{e}_r | \\sim \\mathcal{N}(\\mu_{| \\pmb{e}_r |}, \\sigma_{| \\pmb{e}_r |}^2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mu_{| \\pmb{e} |} = \\alpha_{| \\pmb{e} |} + \\beta_{| \\pmb{e} |} \\cdot X_\\text{uni} + \\varepsilon_{| \\pmb{e} |}, \\\\\n",
    "\\mu_{| \\pmb{e}_r |} = \\alpha_{| \\pmb{e}_r |} + \\beta_{| \\pmb{e}_r |} \\cdot X_\\text{uni} + \\varepsilon_{| \\pmb{e}_r |}.\n",
    "$$\n",
    "\n",
    "The values of $X_\\text{uni}$ are either $0$ if the montage is bipolar or $1$ if it is unipolar. This way, $\\beta$ actually characterises the difference between the two experiments, meaning that if $\\beta \\approx 0$ the two populations are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled model\n",
    "\n",
    "The first models we fit are fully pooled. This means that we do not account for any hierarchy in the data and instead consider all the samples as independent.\n",
    "\n",
    "These models are exactly the ones described above. \n",
    "\n",
    "### Fit the models\n",
    "\n",
    "Weakly informative priors are set automatically for $\\alpha$, $\\beta$ and $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pooled_e = bmb.Model(\"e ~ montage\", data)\n",
    "model_pooled_e_r = bmb.Model(\"e_r ~ montage\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "trace_pooled_e = model_pooled_e.fit(draws=1000, chains=4, random_seed=RANDOM_SEED)\n",
    "trace_pooled_e_r = model_pooled_e_r.fit(draws=1000, chains=4, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We display the probability density of $\\beta$ for both models as well as their $95$% HDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "idx = [\"alpha\", \"beta\", \"sigma\"]\n",
    "summary_pooled_e = az.summary(trace_pooled_e, stat_funcs=FUNC_DICT, extend=False)\n",
    "summary_pooled_e_r = az.summary(trace_pooled_e_r, stat_funcs=FUNC_DICT, extend=False)\n",
    "summary_pooled_e.index, summary_pooled_e_r.index = idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 2.5))\n",
    "plot_posterior(\n",
    "    axs[0],\n",
    "    trace_pooled_e,\n",
    "    summary_pooled_e,\n",
    "    \"montage\",\n",
    "    LABELS[\"e\"],\n",
    "    CAPTIONS[\"e\"],\n",
    "    summary_param=\"beta\",\n",
    "    show_zero=True,\n",
    ")\n",
    "plot_posterior(\n",
    "    axs[1],\n",
    "    trace_pooled_e_r,\n",
    "    summary_pooled_e_r,\n",
    "    \"montage\",\n",
    "    LABELS[\"e_r\"],\n",
    "    CAPTIONS[\"e_r\"],\n",
    "    summary_param=\"beta\",\n",
    "    show_zero=True,\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "display_side_by_side([summary_pooled_e, summary_pooled_e_r], [\"\", \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical model\n",
    "\n",
    "Now, we consider the fact that multiple records were obtained with the same subject.\n",
    "\n",
    "To account for this, the definitions of the intercept $\\alpha$ and the slope $\\beta$ become\n",
    "$$\n",
    "\\alpha_i = \\alpha_\\text{common} + \\alpha_{\\text{sub}_i}, \\\\\n",
    "\\beta_i = \\beta_\\text{common} + \\beta_{\\text{sub}_i}.\n",
    "$$\n",
    "\n",
    "Here, we differenciate the common value of the intercept $\\alpha_\\text{common}$ and of the slope $\\beta_\\text{common}$ from the subject specific contributions $\\alpha_{\\text{sub}_i}$ and $\\beta_{\\text{sub}_i}$. These contributions are modelled as centered normal distributions\n",
    "$$\n",
    "\\alpha_\\text{sub} \\sim \\mathcal{N}(0, \\sigma_{\\alpha_\\text{sub}}), \\\\\n",
    "\\beta_\\text{sub} \\sim \\mathcal{N}(0, \\sigma_{\\beta_\\text{sub}}).\n",
    "$$\n",
    "\n",
    "Hence, the models become\n",
    "$$\n",
    "| \\pmb{e} | \\sim \\mathcal{N}(\\mu_{| \\pmb{e} |, i}, \\sigma_{| \\pmb{e} |}^2), \\\\\n",
    "| \\pmb{e}_r | \\sim \\mathcal{N}(\\mu_{| \\pmb{e}_r |, i}, \\sigma_{| \\pmb{e}_r |}^2),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mu_{| \\pmb{e} |, i} = \\alpha_{| \\pmb{e} |, i} + \\beta_{| \\pmb{e} |, i} \\cdot X_\\text{uni} + \\varepsilon_{| \\pmb{e} |}, \\\\\n",
    "\\mu_{| \\pmb{e}_r |, i} = \\alpha_{| \\pmb{e}_r |, i} + \\beta_{| \\pmb{e}_r |, i} \\cdot X_\\text{uni} + \\varepsilon_{| \\pmb{e}_r |}.\n",
    "$$\n",
    "\n",
    "### Fit the models\n",
    "\n",
    "Once again, weakly informative priors are automatically set for all the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hierarchic_e = bmb.Model(\"e ~ montage + (montage | C(sub))\", data)\n",
    "model_hierarchic_e_r = bmb.Model(\"e_r ~ montage + (montage | C(sub))\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "trace_hierarchic_e = model_hierarchic_e.fit(\n",
    "    draws=1000, chains=4, random_seed=RANDOM_SEED, target_accept=0.9\n",
    ")\n",
    "trace_hierarchic_e_r = model_hierarchic_e_r.fit(\n",
    "    draws=1000, chains=4, random_seed=RANDOM_SEED, target_accept=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Again, we display the posteriors of $\\beta$ and their $95$% HDI for the two metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "idx = [\n",
    "    \"alpha\",\n",
    "    \"beta\",\n",
    "    \"sigma(alpha_sub)\",\n",
    "    *[f\"alpha_sub_{i}\" for i in range(len(data[\"sub\"].unique()))],\n",
    "    \"sigma(beta_sub)\",\n",
    "    *[f\"beta_sub_{i}\" for i in range(len(data[\"sub\"].unique()))],\n",
    "    \"sigma\",\n",
    "]\n",
    "summary_hierarchic_e = az.summary(\n",
    "    trace_hierarchic_e, stat_funcs=FUNC_DICT, extend=False\n",
    ")\n",
    "summary_hierarchic_e_r = az.summary(\n",
    "    trace_hierarchic_e_r, stat_funcs=FUNC_DICT, extend=False\n",
    ")\n",
    "summary_hierarchic_e.index, summary_hierarchic_e_r.index = idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 2.5))\n",
    "plot_posterior(\n",
    "    axs[0],\n",
    "    trace_hierarchic_e,\n",
    "    summary_hierarchic_e,\n",
    "    \"montage\",\n",
    "    LABELS[\"e\"],\n",
    "    CAPTIONS[\"e\"],\n",
    "    summary_param=\"beta\",\n",
    "    show_zero=True,\n",
    ")\n",
    "plot_posterior(\n",
    "    axs[1],\n",
    "    trace_hierarchic_e_r,\n",
    "    summary_hierarchic_e_r,\n",
    "    \"montage\",\n",
    "    LABELS[\"e_r\"],\n",
    "    CAPTIONS[\"e_r\"],\n",
    "    summary_param=\"beta\",\n",
    "    show_zero=True,\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "rows = [\"alpha\", \"sigma(alpha_sub)\", \"beta\", \"sigma(beta_sub)\", \"sigma\"]\n",
    "display_side_by_side(\n",
    "    [summary_hierarchic_e.loc[rows, :], summary_hierarchic_e_r.loc[rows, :]], [\"\", \"\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainweb-tdcs-analysis",
   "language": "python",
   "name": "brainweb-tdcs-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
